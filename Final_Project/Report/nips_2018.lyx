#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2018

% ready for submission
% \usepackage{neurips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{neurips_2018}
% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2018}
\usepackage{CJKutf8}
\AtBeginDvi{\input{zhwinfonts}}
% allow utf-8 input
% use 8-bit T1 fonts
% hyperlinks
\usepackage{url}% simple URL typesetting
% professional-quality tables
\usepackage{amsfonts}% blackboard math symbols
\usepackage{nicefrac}% compact symbols for 1/2, etc.
\usepackage{microtype}% microtypography

\title{ESIM Implementation with FastNLP on Stanford NLI, Mutli NLI, and Chinese NLI}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Linyang He \\
  School of Data Science\\
  Fudan University\\
  \texttt{lyhe15@fudan.edu.cn} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% 
\backslash
nipsfinalcopy is no longer used
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
maketitle
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
Understanding entailment and contradiction is fundamental to understanding
 natural language, and inference about entailment and contradiction is a
 valuable testing ground for the development of semantic representations,
 therefore, Natural Language Inference(NLI) is quite a challenging task
 in NLP field.
 With the large NLI corpus provided(such as SNLI, MultiNLI, XNLI, etc),
 it is possible to train an effective neural network based inference models
 nowadays.
 In this project, we choose the Enhanced LSTM for Natural Language Inference(ESI
M) as the base model.
 ESIM model is a carefully designed sequential inference model based on
 chain LSTMs.
 Besides, we use the FastNLP to help implement.
 FastNLP is a modular Natural Language Processing system based on PyTorch.
 At last, we test our improved ESIM model on Stanford Natural Language Inference
 corpus, Multi-Genre Natural Language Inference corpus and Chinese Natural
 Language Inference corpus.
 The best accuracy was achieved at 68.8% for MultiNLI.
 While for the Chinese NLI, our test score(95.21%) is way much higher than
 the current top performing model(82.38%) in the online CNLI2018 competition,
 which might be a new state-of-the-art.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Natural language inference (NLI) and paraphrase detection are one of the
 main research topics in natural language processing.
 NLI has been addressed using a variety of techniques, including those based
 on symbolic logic, knowledge bases, and neural networks.
 I Natural language inference refers to a problem of determining entailment
 and contradiction between two statements and paraphrase detection focuses
 on determining sentence duplicity.
 
\end_layout

\begin_layout Standard
Specifically, natural language inference is concerned with determining whether
 a natural language hypothesis 
\begin_inset Formula $h$
\end_inset

 can be inferred from a premise 
\begin_inset Formula $p$
\end_inset

.
 There are three relationships between the premise 
\begin_inset Formula $p$
\end_inset

 and the hypothesis 
\begin_inset Formula $h$
\end_inset

:
\emph on
 Entailment
\emph default
,
\emph on
 Neutral
\emph default
, and 
\emph on
Contradiction
\emph default
.
\begin_inset Formula $Entailment$
\end_inset

 suggests that
\begin_inset Formula $h$
\end_inset

 entails 
\begin_inset Formula $p$
\end_inset

, while 
\emph on
Contradiction 
\emph default
shows that 
\begin_inset Formula $p$
\end_inset

 is contrary to 
\begin_inset Formula $h$
\end_inset

, and 
\emph on
Neutral 
\emph default
is in the between.
 Here're three examples.
 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on
A man inspects the uniform of a figure in some East Asian country
\emph default
.
 
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on
The man is sleeping.
\end_layout

\begin_layout Standard
Relationship: 
\emph on
Contradiction 
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on
A soccer game with multiple males playing.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on
Some men are playing a sport.
\end_layout

\begin_layout Standard
Relationship: 
\emph on
Entailment
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on
A smiling costumed woman is holding an umbrella.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on
A happy woman in a fairy costume holds an umbrella.
\end_layout

\begin_layout Standard
Relationship: 
\emph on
Neutral
\end_layout

\end_deeper
\begin_layout Standard
Recent years have seen advances in modeling natural language inference.
 Important contributions on the creation of the richness of the annotated
 dataset for NLI include the Stanford Natural Language Inference(SNLI) dataset
 
\begin_inset CommandInset citation
LatexCommand cite
key "N18-1101"

\end_inset

(Bowman et al., 2015), the Multi-Genre NLI(MultiNLI) corpus(Williams et al.,
 2018), and the Cross-Lingual NLI (XNLI) corpus (Conneau et al., 2018).
 In this project, we use Stanford NLI, which is also widely used in previous
 work.
 The corpus has 570,000 human-written English sentence pairs manually labeled
 by multiple human subjects.
 This makes it feasible to train more complex inference models.
 Besides, we want to see if the very model works well in the English corpus
 would work well in Chinese.
 Therefore, other than SNLI, we use a Chinese Natural Language Inference
 corpus provided by Beijing Language and Culture University as the dataset.
 
\end_layout

\begin_layout Standard
Neural network models, which often need relatively large annotated data
 to estimate their parameters, have shown to achieve the state of the art
 on SNLI.
 As for the contributions on the neural models, papers published on this
 topic use recurrent neural networks (Wang & Jiang, 2016, Wang et al., 2017),
 convolutional neural networks (Mou et al., 2016 ) or feed-forward neural
 networks with soft-alignment and attention (Parikh et al., 2016.).
 
\end_layout

\begin_layout Standard
The ESIM model we choose in this project is a hybrid network model with
 RNN and soft-alignment(or self attention).
 It is provided by Chen et al., 2016
\begin_inset CommandInset citation
LatexCommand cite
key "Chen-Qian:2017:ACL"

\end_inset

.
 While some previous well performed models use quite complex neural network
 structures to achieve their best results, ESIM, instead, provides a comparative
ly less complicated yet excellently-performing model, which suggests that
 the potentials of such sequential inference approaches have not been fully
 exploited yet.
 In this project, we modify the number of the MLP layer from one three.
 This help us achieve quite high test accuracy.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
The remaining part of this report is organized as follows: Section 2 will
 talk about other people's work brifely.
 Section 3 will focus on some background knowledge needed for this project,
 including how to use FastNLP, what is BiLSTM, how self-attention mechanism
 works and so on.
 Section 4 focuses on the ESIM model.
 Section 5 describes the experimental details, including word embedding
 dataset(GloVe
\begin_inset CommandInset citation
LatexCommand cite
key "pennington2014glove"

\end_inset

, SGNS), data pre-processing and processing, experimental parameter settings,
 training and test details.
 Section 6 will be the experimental results and analysis.
 The final part of this article is some ideas for future work.
 
\end_layout

\begin_layout Section
Related Work
\end_layout

\begin_layout Standard
Generally speaking, for NLI, the idea allows neural models to pay attention
 to specific areas of the sentences.
 Much more advanced networks have been developed since Bowman et al provided
 the SNLI dataset.
 Among them, more relevant to ESIM are the approaches proposed by Parikh
 et al.
 (2016) and Munkhdalai and Yu (2016b), which are among the best performing-model
s.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted1.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A Decomposable Attention Model for Natural Language Inference, Parikh et
 al.
 (2016)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
As the Figure 1 shows, Parikh et al.
 (2016) propose a relatively simple but very effective decomposable model.
 The model decomposes the NLI problem into subproblems that can be solved
 separately.
 The figure below depicts the core model architecture which is composed
 of three layers: attention, comparison and aggregation.
 
\end_layout

\begin_layout Standard
Attention layer is implemented using a feed-forward neural network F that
 is applied to both questions separately.
 Outputs of the neural network are then normalized using a softmax function
 and soft-aligned to the second sentence.
 In the comparison level, what the neural network does is to compare soft-aligne
d sentence matrices.
 Similarly to the previous step, a feed-forward neural network is used and
 inputs to the network are concatenated sentence matrices respectively.
 The last part of the core model architecture is the aggregation layer.
 All this layer does is a column-wise sum over the output of the comparison
 network so that they could obtain a fixed-size representation of every
 sentence.
\end_layout

\begin_layout Standard
Also, Munkhdalai and Yu (2016b) proposed much more complicated networks
 that considered sequen tial LSTM-based encoding, recursive neural networks,
 and complex combinations of attention models, which provided around 0.5%
 gain over the results of Parikh et al.
 (2016).
\end_layout

\begin_layout Standard
Besides, although ESIM was the state-of-the-art back to 2016, there are
 many other new models have gained higher testing scores than ESIM did from
 then.
 We choose the current state-of-the-art model, Densely-Connected Recurrent
 and Co-Attentive Network (Seonhoon Kim et al., 2018) to study their model.
 As the figure2 shows, each layer of the model uses concatenated information
 of attentive features as well as hidden features of all the preceding recurrent
 layers.
 Therefore, it can preserve the original and the co-attentive feature informatio
n from the bottommost word embedding layer to the uppermost recurrent layer.
 This from-beginning-to-end attention mechanism help them set the new state-of-t
he-art.
\end_layout

\begin_layout Standard
It was not quite clear if the potential of sequential models like RNN had
 been exploited for NLI when Chen et al., 2016 revisited the problem.
 This is also why they built the ESIM model.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted2.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Densely-Connected Recurrent and Co-Attentive Network , Seonhoon Kim et al.
 '18
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
FastNLP
\end_layout

\begin_layout Standard
We use FastNLP to help build our NLP model.
 FastNLP is provided by Natural Language Processing Group, Fudan University.
 It is a modular Natural Language Processing system based on PyTorch, built
 for fast development of NLP models.
 A deep learning NLP model in FastNLP is the composition of three types
 of modules: 
\emph on
encoder
\emph default

\begin_inset Formula $,$
\end_inset


\emph on
 aggregator, and decoder.
 
\emph default
It can help the users to build some basic natural language models quite
 easily and fast.
 
\end_layout

\begin_layout Standard
In this project, we mainly use FastNLP to preprocess the dataset(fastNLP.core.data
set), build a vocabulary for the datast(fastNLP.core.vocabulary), loader the
 pretrained word embedding vectors(fastNLP.io.embed_loader), train the model
 with the trainer(fastNLP.core.trainer), and test the model(fastNLP.core.tester).
 We found some bugs in fastNLP.
 Also we believe that there should be some functions in some models.
 See more details in Appendix.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted3.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
FastNLP for Text Classification
\end_layout

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Subsection
BiLSTM
\end_layout

\begin_layout Standard
In ESIM, we will use BiLSTM both in the input encoding and inference composition
 stage.
 BiLSTM or Bidirectional LSTM.
 The structure and the connections of a bidirectional LSTM are represented
 in figure 4.
 LSTM is a kind of RNN.
 Briefly, when modeling a sequence, an LSTM employs a set of soft gates
 together with a memory cell to control message flows, resulting in an effective
 modeling of tracking long-distance information/dependencies in a sequence.
\end_layout

\begin_layout Standard
As in BiLSTM, there are two type of connections, one going forward in time,
 which helps learn from previous representations and another going backwards
 in time, which helps learn from future representations.
 Forward propagation is done in two steps: Move from left to right, starting
 with the initial time step we compute the values until we reach the final
 time step.
 Move from right to left, starting with the final time step we compute the
 values until we reach the initial time step.
 Also, those two states’ output are not connected to inputs of the opposite
 direction states.
 Therefore, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$$h =  
\backslash
mbox{BiLSTM}(X)$$
\end_layout

\end_inset

 is equivalent to 
\begin_inset ERT
status open

\begin_layout Plain Layout

$$h_1 = 
\backslash
mbox{LSTM}_1(X),$$
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

$$h_2 = 
\backslash
mbox{LSTM}_2(X),$$
\end_layout

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout

$$h = 
\backslash
mbox{cat}(h_1, h_2).$$
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted4.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
BiLSTM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Attention Mechanism
\end_layout

\begin_layout Standard
Broadly speaking, a neural attention mechanism equips a neural network with
 the ability to focus on a subset of its inputs (or features), in other
 words, it selects specific inputs.
 As the Figure 5 shows, the attention in Seq2Seq model is actually a vector.
 It helps the decoder to decide which part of encoder is input for current
 time step.
 In this way, the decoder pays ``attention'' to the specific time step in
 the encoder.
 While for the alignment, the words in the left pay ``attention'' to some
 certian words above - which are also the important words(white area).
 
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $a$
\end_inset

 is a attention vector, for soft attention, it multiplies features with
 a soft mask of values between zero and one, therefore, 
\begin_inset Formula $a∈[0,1]^{k}$
\end_inset

.
 While for hard attention, those values are constrained to be exactly zero
 or one, namely 
\begin_inset ERT
status open

\begin_layout Plain Layout

$a 
\backslash
in 
\backslash
{0,1
\backslash
}^k$
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted5.png
	scale 30

\end_inset


\begin_inset Graphics
	filename pasted6.png
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Seq2Seq with attention(left), alignment (right)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Soft Alignment
\end_layout

\begin_layout Standard
Soft attention or soft alignment, is usually used in semantic relatedness
 measures.
 In this approach, we can compare the neural word embeddings to compute
 the relatedness between words across both the sentences, thus producing
 the soft alignment matrix.
 The word embedding could be pretrained word vectors or output of some embedding
 layer.
 In ESIM, as we will talk as below, we use the hidden states(output) of
 the BiLSTM to compute soft alignment.
 
\end_layout

\begin_layout Section
ESIM
\end_layout

\begin_layout Standard
Enhanced Sequential Inference Model ( 
\series bold
ESIM
\series default
 ) are composed of the following major components: input encoding, local
 inference modeling, and inference composition, as showing in the left part
 of Figure 6.
 Considering that Chen et al.
 spent about 40 hours on Nvidia-Tesla K40M to train tree-LSTM(right part
 of Figure 6), which means that we might need more than 120 hours to train
 the tree-ESIM model (the ESIM model that takes Chen et al.
 about 6 hours costs us more than 18 hours), we don't think that we have
 enough computing resources and time to train this model.
 So in this project, we focus on the ESIM.
 
\end_layout

\begin_layout Standard
As for the notation, we denote the two sentences as 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
mathbf{a} = (
\backslash
mathbf{a}_1 ,...,
\backslash
mathbf{a}_{l_a})$ 
\end_layout

\end_inset

and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
mathbf{b} = (
\backslash
mathbf{b}_1 ,...,
\backslash
mathbf{b}_{l_b})$ 
\end_layout

\end_inset

, where 
\begin_inset Formula $\mathbf{a}$
\end_inset

 is a premise and 
\begin_inset Formula $\mathbf{b}$
\end_inset

 a hypothesis.
 The 
\begin_inset Formula $\mathbf{a}$
\end_inset

 or 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
mathbf{b}_j 
\backslash
in 
\backslash
mathbb{R}^l$
\end_layout

\end_inset

 is an embedding of 
\begin_inset Formula $l$
\end_inset

 -dimensional vector, which can be initialized with pretrained word vectors.
 The goal is to predict a label 
\begin_inset Formula $y$
\end_inset

 that indicates the logic relationship between
\begin_inset Formula $\mathbf{a}$
\end_inset

 and 
\begin_inset Formula $\mathbf{b}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted7.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A high-level view of the hybrid neural inference networks
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Input Encoding
\end_layout

\begin_layout Standard
In this layer, we use BiLSTM to embed the word vectors in premise and hypothesis.
 We denotethe hidden (output) state given by the BiLSTM as 
\begin_inset Formula $\mathbf{\bar{a}_{i}}$
\end_inset

 at time 
\begin_inset Formula $i$
\end_inset

 with respect to the input sequence 
\begin_inset Formula $\mathbf{a}$
\end_inset

.
 The same is applied to 
\begin_inset Formula $\mathbf{\bar{b}_{j}}$
\end_inset

 :
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{\bar{a}_{i}}=\textrm{BiLSTM}(\mathbf{a},i),∀i∈[1,...,l_{a}],$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{\bar{b}_{j}}=\textrm{BiLSTM}(\mathbf{b},j),∀j∈[1,...,l_{b}].$
\end_inset


\end_layout

\begin_layout Standard
In some way, BiLSTM turns the general word vectors into new embeddings,
 which introduce a lot of useful information about the context.
 The new embeddings could represent not just the word itself, but also the
 relationship among words in the same sentence(premise or hypothesis).
\end_layout

\begin_layout Subsection
Local Inference Modeling
\end_layout

\begin_layout Subsubsection
Locality of inference
\end_layout

\begin_layout Standard
Basically, this layer is the most important part in the whole model to determine
 the overall inference between premise and hypothesis.
 The model in this layer could help collect local inference for words and
 their context.
 The soft alignment layer caculates the attention weights as the similarity
 with respect to a hidden state pair 
\begin_inset Formula $<\mathbf{\bar{a}_{i},}\bar{\mathbf{b}}_{j}>$
\end_inset

between a premise and a hypothesis as
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $e_{ij}=\mathbf{\bar{a}}_{i}^{T}\bar{\mathbf{b}}_{j}$
\end_inset

.
\end_layout

\begin_layout Standard
Rather than using a feedforward neural network like in Parikh et al.
 (2016) to map the original word representation for computing 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $e_{ij}$
\end_inset

, ESIM chooses BiLSTM, which encodes the information in premise and hypothesis
 quite well and achieves better performance.
 We believe this might introduce the correlation information between words
 from different sentences(premise and hypothesis).
\end_layout

\begin_layout Subsubsection
Local inference collected over sequences 
\end_layout

\begin_layout Standard
Local inference is used to computer the local relevance between a premise
 and a hypothesis.
 For the hidden state of a word in a premise, i.e., 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{\bar{a}_{i}}$
\end_inset

 (encoding both the word itself and its context, we can define a new embedding
 vector denoting the word in premise as the summary of relevant semantics
 in the hypothesis which is a kind of weighted 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $\mathbf{\bar{b}_{j}}$
\end_inset

:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\boldsymbol{\mathbf{\tilde{a}}}_{i}=\sum_{j=1}^{l_{b}}\dfrac{\textrm{exp}(e_{ij})}{\sum_{k=1}^{l_{b}}\textrm{exp}(e_{ik})}\bar{\mathbf{b}}_{j,}\forall i\in[1,...,l_{a}],$
\end_inset


\end_layout

\begin_layout Standard
and it is the same for the new defined hypothesis word vector:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\boldsymbol{\mathbf{\tilde{b}}}_{j}=\sum_{i=1}^{l_{a}}\dfrac{\textrm{exp}(e_{ij})}{\sum_{k=1}^{l_{a}}\textrm{exp}(e_{kj})}\mathbf{\bar{a}}_{i,}\forall i\in[1,...,l_{a}],$
\end_inset


\end_layout

\begin_layout Standard
In this stage, the embedding vectors encode not just the word itself, but
 also the context information in the same sentence, and the relevance informatio
n of the other sentence.
 
\end_layout

\begin_layout Subsubsection
Enhancement of local inference information
\end_layout

\begin_layout Standard
Up to now, we have two types of new embedding vectors, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{\bar{a}_{i}}$
\end_inset

 and
\begin_inset Formula $\boldsymbol{\mathbf{\tilde{a}}}_{i}$
\end_inset

.
 To enhance the local inference, we should make maximum use of these vectors.
 We compute the difference and the element-wise product for the tuple 
\begin_inset Formula $<\bar{\mathbf{a}},\mathbf{\tilde{a}}>$
\end_inset

 as well as for 
\begin_inset Formula $<\mathbf{\bar{b}},\mathbf{\tilde{b}}>$
\end_inset

.We expect that such operations could help sharpen local inference information
 betwen elements in the tuples, thus capture the inference relationships
 such as contradiction.
 The difference and element-wise product are then concatenated with the
 original vectors,
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{m}_{a}=[\mathbf{\bar{a};\mathbf{\tilde{a}};\mathbf{\bar{\mathbf{a}}-\tilde{a}}\mathbf{;\bar{\mathbf{a}}\odot\tilde{a}}}]$
\end_inset


\end_layout

\begin_layout Standard
\align center

\emph on
\begin_inset Formula $\mathbf{m}_{b}=[\mathbf{\bar{b};\mathbf{\tilde{b}};\mathbf{\bar{\mathbf{b}}-\tilde{b}}\mathbf{;\bar{\mathbf{b}}\odot\tilde{b}}}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\mathbf{m_{a}}$
\end_inset

and
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{m}_{b}$
\end_inset

would be then fed into the inference composition layer to predict the final
 inference label.
 
\end_layout

\begin_layout Subsection
Inference Composition
\end_layout

\begin_layout Standard
To obtain the overall inference relationship between the premise and the
 hypothesis, we build a composition layer to compose the enhanced local
 inference information
\begin_inset Formula $\mathbf{m_{a}}$
\end_inset

and
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{m}_{b}$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
The composition layer
\end_layout

\begin_layout Standard
Still using BiLSTM here, we could compose local inference information sequential
ly.
 More specifically, we use a 1-layer feedforward neural network with the
 ReLU activation.
 
\end_layout

\begin_layout Subsubsection
Pooling 
\end_layout

\begin_layout Standard
We consider both average and max pooling here and concatenate all these
 pooled vectors to form a final length fixxing vector 
\begin_inset Formula $v$
\end_inset

.
 
\begin_inset Formula $v$
\end_inset

 can be computed as followsing:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{v}_{a,\textrm{ave}}=\sum_{i=1}^{l_{a}}\dfrac{\mathbf{v}_{a,i}}{l_{a}},\mathbf{v}_{a,\textrm{max}}=\textrm{ma}\textrm{x}_{i=1}^{l_{a}}\mathbf{v}_{a,i}$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{v}_{b,\textrm{ave}}=\sum_{j=1}^{l_{b}}\dfrac{\mathbf{v}_{b,j}}{l_{b}},\mathbf{v}_{b,\textrm{max}}=\textrm{ma}\textrm{x}_{j=1}^{l_{b}}\mathbf{v}_{b,j}$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\mathbf{v}=[\mathbf{v}_{a,\textrm{ave}};\mathbf{v}_{a,\textrm{max}};\mathbf{v}_{b,\textrm{ave}};\mathbf{v}_{b.\textrm{max}}]$
\end_inset


\end_layout

\begin_layout Subsubsection
Prediction and our improvement
\end_layout

\begin_layout Standard
We feed 
\begin_inset Formula $\mathbf{v}$
\end_inset

 into a final multilayer perceptron (MLP) classifier.
 In Chen et al's model, the MLP has a hidden layer with tanh as the activation
 function and softmax as the output layer.
 We believe that the MLP would be a good layer for fine-tuning.
 After different experiments, we find that a three-layer MLP with ELU as
 the activation function could provide a great test score.
\end_layout

\begin_layout Section
Experiment Setup
\end_layout

\begin_layout Subsection
Data
\end_layout

\begin_layout Standard
In our experiment, we test ESIM both on English and Chinese corpus.
 For English experiments, we use GloVe as the pretrained embedding weights.
 For the NLI corpus in English experiments, we test both on Staford NLI
 and Multi-Genre NLI.
 For the Chinese experiment, we use the pretrained SGNS Wikipedia embedding
 introduced in Analogical Reasoning on Chinese Morphological and Semantic
 Relations.
 (Shen Li et al., 2018) For the NLI corpus in Chinese experiment, we use
 Chinese Natrual Language Inference corpus provided by Beijing Language
 and Culture University.
 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
See more details on https://github.com/blcunlp/CNLI 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GloVe
\end_layout

\begin_layout Standard
GloVe, or Global Vectors for Word Representation, is an unsupervised learning
 algorithm for obtaining vector representations for words.
 Training is performed on aggregated global word-word co-occurrence statistics
 from a corpus, and the resulting representations showcase interesting linear
 substructures of the word vector space.
 Usually, we use the pre-trained GloVe word embedding provided by Stanford
 University.
 From Figure 7, we could find that GloVe performs better than the traditional
 word2vec embedding models CBoW and Skip-Gram.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted8.png
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
GloVe vs Word2Vec
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Chinese Word Embedding
\end_layout

\begin_layout Standard
We use the Wikipedia Chinese word vector mentioned in Analogical Reasoning
 on Chinese Morphological and Semantic Relations.
\begin_inset CommandInset citation
LatexCommand cite
key "P18-2023"

\end_inset

(Shen Li et al., 2018)
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Download the pretrained Chinese word vectors here https://github.com/Embedding/Ch
inese-Word-Vectors
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted9.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Chinese Word Vector
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are many different pretrained word vectors based on different corpora
 incuding Wikipedia, Baidubaike, Sogou News, People's Daily, Zhihu QA, Financial
 News, Weibo, etc.
 Also, different word vectors have different performances as the Figure
 9 shows.
 Howover, considering the importing speed, we choose the minimal one - Wikipedia.
 Besides, the data format of Chinese word vector is the same as GloVe.
 Therefore, we could use fastNLP to load the embedding vector directly.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted10.png
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Different word vectors' performances on CA_translated and CA8.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Stanford NLI
\end_layout

\begin_layout Standard
The SNLI corpus is a collection of 570k human-written English sentence pairs
 manually labeled for balanced classification with the labels entailment,
 contradiction, and neutral, supporting the task of natural language inference
 (NLI), also known as recognizing textual entailment (RTE).
 The aim is to serve both as a benchmark for evaluating representational
 systems for text, especially including those induced by representation
 learning methods, as well as a resource for developing NLP models of any
 kind.
 
\end_layout

\begin_layout Standard
Actually, there are 5 labels in each NLI line.
 If any one of the three labels was chosen by at least three of the five
 annotators, it was chosen as the
\emph on
 gold label
\emph default
.
 If there was no such consensus, which occurred in about 2% of cases, we
 assigned the placeholder label '-'.
 In our project, we just use the 
\emph on
gold label
\emph default
.
 There's an SNLI example in the Introduction part already, so we won't give
 another example here.
\end_layout

\begin_layout Subsubsection
Multi-Genre NLI 
\end_layout

\begin_layout Standard
The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced
 collection of 433k sentence pairs annotated with textual entailment information.
 The corpus is modeled on the SNLI corpus, but differs in that covers a
 range of genres of spoken and written text, and supports a distinctive
 cross-genre generalization evaluation.
 
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted11.png
	scale 42

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Multi-Genre NLI Corpus
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
As we can see from examples in Figure 10, different from the SNLI, in which
 the sentences are derived from only a single text genre image captions,
 there are many different genres here:
\emph on
 GOVERNMENT, SLATE, TELEPHONE, TRAVEL, FICTION, and 9/11 REPORT, FACE-TO-FACE,
 LETTERS, OUP,VERBATIM.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted12.png
	scale 38

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Multi-Genre NLI Corpus
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
All of the genres appear in the test and development sets, but only five
 are included in the training set(the first five).
 Models thus can be evaluated on both the matched test examples, which are
 derived from the same sources as those in the training set, and on the
 mismatched examples.
 The dev dataset is split into matched and dismatched part.
 In this project, we test on both the matched and mismatched.
\end_layout

\begin_layout Subsubsection
Chinese NLI
\end_layout

\begin_layout Standard
CNLI dataset is firstly provided for the Chinese Natural Language Inference
 (CNLI) share task on The Seventeenth China National Conference on Computational
 Linguistics, CCL 2018
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Task3, see more details on http://www.cips-cl.org/static/CCL2018/call-evaluation.ht
ml
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Both the train and dev set in CNLI are tab-separated format.
 Each line in the train (or dev) file corresponds to an instance, and it
 is arranged as
\emph on
: sentence-id, premise, hypothesis, label.
 
\emph default
Here are some examples
\emph on
.
 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

一个小男孩正在打一个黄色的球。
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

一个小男孩在读书。
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Relationship: 
\emph on
Contradiction
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

一个小男孩在铁轨上行走。		
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

一个小男孩坐火车。
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Relationship: 
\emph on
Neutral
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Formula $p$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

一对夫妇正在观看3D电影。				
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $h$
\end_inset

: 
\emph on

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{CJK*}{UTF8}{zhsong}
\end_layout

\begin_layout Plain Layout

有些人正在看电影。
\end_layout

\begin_layout Plain Layout


\backslash
end{CJK*}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Relationship: 
\emph on
Entailment
\end_layout

\end_deeper
\begin_layout Subsection
Experiment
\end_layout

\begin_layout Standard
Considering that all the datasets provide training, dev and test set, we
 don't have to split the dataset on our own.
 As for the parameters setting for the training stage, we keep the same
 as Chen et al.
 did in the original paper.
 The parameters setting are as follows: 
\end_layout

\begin_layout Itemize
batch size: 32
\end_layout

\begin_layout Itemize
learning rate: initially 0.0004
\end_layout

\begin_layout Itemize
optimizer: Adam method with 0.9 as the first momentum and 0.999 the sencond
\end_layout

\begin_layout Itemize
embeddding dimension: 300
\end_layout

\begin_layout Itemize
hidden size in BiLSTM: 300
\end_layout

\begin_layout Itemize
num of linear layer in MLP: 3
\end_layout

\begin_layout Itemize
dropout rate: 0.5
\end_layout

\begin_layout Itemize
activate function: ELU
\end_layout

\begin_layout Itemize
hidden size in MLP: 300
\end_layout

\begin_layout Itemize
padding index: 0
\end_layout

\begin_layout Itemize
out of vocabulary index: 1
\end_layout

\begin_layout Standard
Besides, there's a built-in SNLI model in FastNLP.
 The forward function of this model is: forward(
\emph on
premise, hypothesis, premise_len, hypothesis_len
\emph default
), where the 
\emph on
premise_len
\emph default
 is a mask Tensor of 
\emph on
premise
\emph default
, recording if the word is a padding.
 However, we are not quite sure how to get a mask Tensor as the input with
 the only usage of FastNLP, considering the padding function is encapsulated
 in FastNLP.
\end_layout

\begin_layout Standard
Also, we noticed that there's no loading pretrained word embedding function
 in the built-in SNLI model.
 So we add another set of experiments where we don't do word embedding.
 Instead, we use the index of each word in the dataset as the input.
 
\end_layout

\begin_layout Section
Result
\end_layout

\begin_layout Subsection
Result for English Experiment
\end_layout

\begin_layout Standard
Considering the dataset is very large, training is quite time consuming.
 Hence, we just let the ESIM model on SNLI run more than 40 epochs.
 For those models on MultiNLI, we just run about 10 epochs.
 
\end_layout

\begin_layout Standard
Here's the result for SNLI.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
dev score
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
test score
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
our ESIM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
83.66
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
82.72
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
our ESIM, no emb
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
89.62
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
89.70
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESIM, Chen et al.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
92.60
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
88.00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Densely-Connected Recurrent and Co-Attentive Network*
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
95.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90.10
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Result for SNLI, *current state-of-the-art
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here's the result for MultiNLI.
 Notice that MultiNLI isn't avalaible yet when Chen et al.
 proposed ESIM in 2016.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
dev score
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
test score, matched
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
test score, mismatched
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Most Frequent Class
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
36.50
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35.60
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CBoW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
65.20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64.60
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BiLSTM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
67.50
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
67.10
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
ESIM, Bowman et al.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
72.40
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
72.90
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Our ESIM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
68.62
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
68.78
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
68.79
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Our ESIM, no emb
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
67.03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
66.72
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
67.88
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Result for MultiNLI
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Noticed that out ESIM doesn't perform well as Boman et al.'s ESIM does.
 This is because that we don't have enough time to train the model on the
 MultiNLI dataset.
 Nonetheless, out owe-trained model still beats all the three other models.
 This suggests that ESIM indeed is a strong model in the Natural Language
 Inference field.
 
\end_layout

\begin_layout Subsection
Result for Chinese Experiment
\end_layout

\begin_layout Standard
You can see 
\begin_inset CommandInset href
LatexCommand href
name "this page"
target "https://github.com/blcunlp/CNLI/blob/65fdc7a693c4e8e7b69b477510625b11754b2553/CNLI2018%20Evaluation%20Result.md"

\end_inset

 to view the current evaluation result in the CNLI2018 competetion.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Team
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Test Score
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Our Team
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
ESIM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
95.21
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Out Team
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
ESIM, no emb
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
92.10
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
water
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
cnn+lstm
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
82.38
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
zzunlp
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
nlpc
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
78.28
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BaiduZhizhu
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Excailibur
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
76.92
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GDUFSER
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
76.18
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ray_li
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
74.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
INTSIG_AI
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
73.03
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yonseiiii
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
decom-att
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
72.42
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Baseline
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESIM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
72.22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
_503
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bi
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
68.48
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hiter
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DAM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60.90
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Result for CNLI
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The current highest test score in the CNLI2018 competetion is 0.8238.
 Our test score is way much higher than the current top1 model.
 Therefore, we could say that ESIM indeed works quite well not just for
 English corpus, but also on Chinese NLI task.
\end_layout

\begin_layout Standard
According to all the experiments above, we foud that no matter what the
 dataset is, or no matter what the language is, word embedding can always
 enhance the performance.
 This also suggests that the FastNLP built-in SNLI model might consider
 to add this function.
\end_layout

\begin_layout Standard
From the result above, we could notice that all the models' performance
 on Multi-Genre NLI corpus are not much impressive, which suggests there's
 still a lot of potential of this specific task to be exploited.
\end_layout

\begin_layout Section
Feature Work
\end_layout

\begin_layout Standard
According to time and resources limitation, we could not train a Tree-ESIM
 in this project.
 But we are extremely interested in encoding syntactic information in the
 ESIM model.
 Moreover, there are a banch of ways to introducing syntactic information
 into a NLP model such as multi-task learning with POS, etc.
 We want to investigate if all forms of syntactic information adding would
 help enhance the performance, or just the tree structured LSTM based on
 a parsing tree would work.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "citation"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
